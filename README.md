# ğŸ“š End-to-End RAG System (Local, Modular, Production-Ready)

This repository contains a **fully local, modular Retrieval-Augmented Generation (RAG) pipeline** built using Python.  
It supports **multi-format document ingestion**, **semantic search with FAISS**, and **LLM-powered summarization using Ollama (llama2)**.

---

## ğŸš€ Features

### ğŸ“‚ Multi-format document ingestion
- PDF  
- TXT  
- CSV  
- Excel  
- Word  
- JSON  

### âœ‚ï¸ Smart document chunking
- Recursive character-based splitting

### ğŸ§  Dense embeddings
- SentenceTransformers (`all-MiniLM-L6-v2`)

### ğŸ“¦ FAISS vector database
- Persistent local storage

### ğŸ” Semantic retrieval
- Top-k similarity search

### ğŸ¤– Local LLM inference
- Ollama (`llama2:latest`)

### ğŸ”’ Fully local & private
- No cloud APIs  
- No data leakage

---

## ğŸ—ï¸ Project Structure
Project Root
â”‚
â”œâ”€â”€ data/  
â”‚   â””â”€â”€ Raw documents (PDF, CSV, TXT, Excel, Word, JSON)
â”‚
â”œâ”€â”€ faiss_store/  
â”‚   â””â”€â”€ Persistent FAISS index and metadata
â”‚
â”œâ”€â”€ src/  
â”‚   â”œâ”€â”€ data_loader.py        - Multi-format document ingestion  
â”‚   â”œâ”€â”€ embedding.py          - Document chunking and embedding pipeline  
â”‚   â”œâ”€â”€ vectorstore.py        - FAISS vector store implementation  
â”‚   â””â”€â”€ search.py             - RAG search and summarization logic  
â”‚
â”œâ”€â”€ requirements.txt          - Project dependencies  
â””â”€â”€ README.md                 - Project documentation


## ğŸ”„ Architecture Overview

Documents
â†“
Data Loader
â†“
Text Chunking
â†“
Embeddings (SentenceTransformers)
â†“
FAISS Vector Store
â†“
Semantic Retrieval
â†“
Ollama (llama2)
â†“
Answer / Summary



## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
git clone https://github.com/RushikeshPati20/Traditional_RAG_Pipeline

### 2ï¸âƒ£ Install Dependencies
Copy code
pip install -r requirements.txt

### 3ï¸âƒ£ Install & Run Ollama
Copy code
ollama pull llama2

### â–¶ï¸ Usage
Build Vector Store & Query
Copy code
python src/search.py
Example query:

text
Copy code
"What is attention mechanism?"
The system retrieves relevant document chunks and generates a concise summary using a local LLM.

### ğŸ§ª Example Use Cases
Document Q&A
Knowledge base search
Research paper summarization
Internal document assistant
Local GenAI experimentation

### ğŸ”® Future Improvements
Hybrid search (BM25 + embeddings)
Metadata filtering
Better chunking strategies
Streaming LLM responses
API / Web UI integration

### ğŸ› ï¸ Tech Stack
Python
LangChain
SentenceTransformers
FAISS
Ollama (llama2)
NumPy

### ğŸ“Œ Why This Project?
This project demonstrates how real-world RAG systems are structured:
Clear separation of concerns
Reusable components
Local-first GenAI architecture
Production-style vector search
